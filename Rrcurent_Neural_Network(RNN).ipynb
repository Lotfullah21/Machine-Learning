{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rrcurent Neural Network(RNN).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPEd61xffkcB7IGzky760wU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lotfullah21/Open-CV/blob/main/Rrcurent_Neural_Network(RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN\n",
        "RNNs are a particular type of state machines with multidimension vector of real values as the sates.\n",
        "Here we same as Convnets we are having shared weights, but in RNNs those weights are tmeporal. we can take advantage of this shared weights to have a compact solution while doing forward and backward pass.\n",
        "as we are having a sharing weights accrosss all unrlolled layers, a small change in that will effect whole network, this is critical while we are optimizing loss with respect to weights. \n",
        "here also the previous states have effect on the future states, this can be defined as one of the main point about the RNNs."
      ],
      "metadata": {
        "id": "QKrPrEAylVyw"
      }
    }
  ]
}