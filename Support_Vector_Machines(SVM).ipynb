{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Support Vector Machines(SVM).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyML/QGGoJtOr1d+1gafQamf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lotfullah21/Machine-Learning/blob/main/Support_Vector_Machines(SVM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CGuSpV8dbgLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Support Vector Machine(SVM):\n",
        "it is an extension of the support vector classifier that results from enlarging the feature space in a specific way using kernels.\n",
        "The SVM algorithm outputs an optimal Hyperplane that categorizes new examples.\n",
        "## Kerneling:\n",
        "Mapping data to a higher dimensional space is known as kernenling, we have different functions to do this, but the most important ones are\n",
        "* Linear \n",
        "* Polynomial \n",
        "* Radial based funcions(RBF)\n",
        "* Sigmoid\n",
        "\n",
        "### Why Kerneling: \n",
        "most often our real data are not linearly seperable, kernels used here to extned there feature vector to higher dimensional space so that they can be classified.\n",
        "\n",
        "in SVM the goal is to maximize the margin between from the HyperPlane\n",
        "#### Hyperplane: \n",
        "it divides our data into two classes, on which is greater than zero to the right side of the hyper plane and the next class to the left side of the hyperplane:\n",
        "#### Margin:\n",
        "Margin is the distance from Hyperplane to the closest data point.\n",
        "#### Support Vectors: \n",
        "these are the ones that define the shape,or position of the hyper plane. we have to be very careful while choosing, slightest change can cause a huge change in our hyperplane.\n",
        "#### Why SVMs:\n",
        "in fact perceptron and SVMs are doing the same thing, but with one difference:\n",
        "in perceptrons, we have many classes of hyperplanes, But in Support vector machine we also have many, but the algorithm returns the one that has maximum margin, so that it won't be prune much to overfitting. "
      ],
      "metadata": {
        "id": "Xop1Dto8WwgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM works by mapping data to a high-dimensional feature space so that data points can be categorized, even when the data are not otherwise linearly separable. A separator between the categories is found, then the data is transformed in such a way that the separator could be drawn as a hyperplane. Following this, characteristics of new data can be used to predict the group to which a new record should belong.\n",
        "\"IBM course\"\n"
      ],
      "metadata": {
        "id": "YqXmnKf7bh4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9h9ZXRpnbjjK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}